{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSU DSCI 369 Lab 13\n",
    "Instructor: Emily J. King\n",
    "Spring 2024\n",
    "\n",
    "Goals: Get more (now explicit) practice with eigenvectors and eigenvalues.\n",
    "Play around with power iteration to find an eigenvector for the largest eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy.linalg import eigvals\n",
    "from numpy.linalg import eig\n",
    "from numpy.linalg import inv\n",
    "from poweriter import poweriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvalues of diagonal matrices\n",
    "\n",
    "Recall what multiplying by a diagonal matrix does: it scales the first coordinate by the first diagonal element, the second coordinate by the second diagonal element, and so on.  So, what should the eigenvalues and eigenvectors be?  Discuss.\n",
    "\n",
    "Now we test by making a 5x5 diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 4, 0, 0],\n",
       "       [0, 0, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 3]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F=np.diag(np.array([5, 1, 4, 2, 3]))\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the eigenvalues alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 1., 4., 2., 3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the eigenvalues are simply the diagonal elements of the diagonal matrix, but they may be listed in a different order due to the algorithm used to compute them.  \n",
    "\n",
    "Now let's see the command to compute the eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 1., 4., 2., 3.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, U = eig(F)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the eig command returns an array and a matrix. The array is the same thing returned by eigvals. When possible, the matrix returned is an orthogonal matrix: that is, the columns form an orthonormal basis for R^n. Otherwise, the columns are unit norm but not necessarily orthogonal. The columns of the matrix are eigenvectors corresponding to the eigenvalues listed in the array.  IF it is possible to decompose a matrix in the form UDU^(-1) that we've played around with for the last 3 labs, then U above and D formed as the diagonal matrix with diagonal d above, will work.\n",
    "\n",
    "Let's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(U@np.diag(d)@inv(U),F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are the same.\n",
    "\n",
    "Note that any scalar multiple of the jth column of U above is still an eigenvector for the jth eigenvalue since eigenspaces are vector spaces.\n",
    "\n",
    "Now let's test another diagonal matrix: the 7x7 identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E=np.eye(7)\n",
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think the eigenvalues and eigenvectors are? Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, U = eig(E)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you interpret what you see?  \n",
    "\n",
    "Also note that an eigenvalue can be repeated if the eigenspace is larger than 1 dimension.  In that case, the eigenvectors returned corresponding to the same value are an orthonormal basis for the space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvalues of MDM^(-1)\n",
    "\n",
    "We've been playing with matrices of this form for 3 labs now.  Now, let's explicitly compute the eigenvalues / eigenvectors.  To make the patterns easier to see, we will use an integer matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3, -3, -3, -3,  0],\n",
       "       [ 2, -3, -2, -2,  0],\n",
       "       [-1,  3, -1,  1, -1],\n",
       "       [-2,  3,  2,  2,  2],\n",
       "       [-1,  1, -3,  1, -2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M=np.array([[-3, -3, -3, -3, 0],[2, -3, -2, -2, 0],[-1, 3, -1, 1, -1],[-2, 3, 2, 2, 2],[-1, 1, -3, 1, -2]])\n",
    "M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remember what the diagonal matrix above looked like and then compute MFM^(-1):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 4, 0, 0],\n",
       "       [0, 0, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.5       ,  0.21428571,  0.85714286,  1.5       ,  1.07142857],\n",
       "       [-1.        ,  5.71428571,  2.85714286,  1.        , -0.42857143],\n",
       "       [ 0.5       , -1.        ,  0.        ,  0.        ,  1.5       ],\n",
       "       [ 1.        , -2.71428571, -2.85714286,  2.        ,  0.42857143],\n",
       "       [ 0.5       ,  0.35714286, -0.57142857,  0.5       ,  3.78571429]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=M@F@inv(M)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the eigenvalues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 2., 1., 4., 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see? Discuss.\n",
    "\n",
    "Let's compute the eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 2., 1., 4., 3.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_A, U_A = eig(A)\n",
    "d_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.88247202e-01, -6.88247202e-01,  4.93196962e-01,\n",
       "        -5.77350269e-01,  4.93888830e-16],\n",
       "       [-4.58831468e-01, -4.58831468e-01,  4.93196962e-01,\n",
       "        -3.84900179e-01,  2.82616643e-15],\n",
       "       [ 2.29415734e-01,  2.29415734e-01, -4.93196962e-01,\n",
       "        -1.92450090e-01, -3.33333333e-01],\n",
       "       [ 4.58831468e-01,  4.58831468e-01, -4.93196962e-01,\n",
       "         3.84900179e-01,  6.66666667e-01],\n",
       "       [ 2.29415734e-01,  2.29415734e-01, -1.64398987e-01,\n",
       "        -5.77350269e-01, -6.66666667e-01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what's going on?  From the ordering of the output, the first column of U_A corresponds to the eigenvalue of 5.  From the previous labs, we know that since 5 is the first entry of the diagonal matrix F, if we multiply A times the first column of M, it must be 5 times that column.  Let's normalize that column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6882472 ,  0.45883147, -0.22941573, -0.45883147, -0.22941573])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[:,0]/norm(M[:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should look like either the first column or negative the first column of U_A.  Let's test (replace the minus with plus if looks negated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(-M[:,0]/norm(M[:,0]),U_A[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvectors of non-diagonalizable matrices\n",
    "\n",
    "Until now in the labs, we were always playing with matrices of the form MDM^(-1) for M nxn invertible and D nxn diagonal. Let's now consider a matrix that cannot be written in that form, a shear matrix.\n",
    "\n",
    "Let S be a 2x2 matrix that shears by a factor of 3 downwards.  What do we know must stay in place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=np.array([[1, 0],[-3, 1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to compute the eigenvalues of S.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are 2 ones. Does that mean that there are two dimensions of vectors in R^2 fixed by shearing?  Does that make sense?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, U = eig(S)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 7.40148683e-17],\n",
       "       [1.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can hopefully see what has happened.  Both columns of U are the same (up to floating point arithmetic).  In particular, that means that U is not invertible, and thus UDU^(-1) isn't defined.  Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.35107989e+16,  1.00000000e+00],\n",
       "       [ 1.35107989e+16,  0.00000000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy should have returned a warning since the two columns were within floating point arithmetic of each other.  Instead, it returned a garbage matrix that has almost the largest number the computer can handle in one entry, and minux that number in another.  In real life, this matrix is not invertible.\n",
    "\n",
    "The issue is that S is 2x2 but only has one dimension of eigenvectors: the y-axis.  Said another way: S only has one eigenspace, for eigenvalue 1, and that eigenspace is only 1-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power iteration\n",
    "\n",
    "When a matrix is \"nice enough\", if you take a random vector and multiply it by higher and higher powers of the matrix, you get output that points closer and closer to the direction of an eigenvector for the largers eigenvalue.  We saw this a bit when playing around with the transition matrix: higher powers applied to the two starting vectors we tried (sunny today vs. gray today) always emphasized the steady state vector.  \n",
    "\n",
    "We can do this for other matrices which have largest eigenvalue larger than 1. To make sure that the vector norms aren't getting too big for the computer, we can normalize.  So, the idea is, multiply a random vector by our matrix, normalize this output, then mulitply that by the matrix and repeat.  Take a look at the code in poweriter.py and discuss.\n",
    "\n",
    "Let's try this with the transition matrix from lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98058068, 0.19611614])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P=np.array([[9/10, 1/2],[1/10, 1/2]])\n",
    "xout=poweriter(P,np.random.rand(2),1000)\n",
    "xout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the normalization of the vector we know to be the steady state vector (i.e., a vector with eigenvalue 1, while the other eigenvalue is 2/5 < 1) to the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(xout,np.array([5/6, 1/6])/norm(np.array([5/6, 1/6])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that power iteration output the normalization of the steady state vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same thing with the matrix A above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xout=poweriter(A,np.random.rand(5),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of U_A is an eigenvector for the largest eigenvalue. It is already normalized, so we can directly compare it to the output of power iteration. If you get false, negate the column from U_A and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(xout,U_A[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "\n",
    "1a. Normalize the other columns of M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        , -0.33333333,  0.66666667, -0.66666667])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[:,1]/norm(M[:,1])\n",
    "M[:,2]/norm(M[:,2])\n",
    "M[:,3]/norm(M[:,3])\n",
    "M[:,4]/norm(M[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Test to see if they are the same with the \"correct corresponding\" column of U_A.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(-M[:,1]/norm(M[:,1]),U_A[:,2]))\n",
    "print(np.allclose(M[:,2]/norm(M[:,2]),U_A[:,3]))\n",
    "print(np.allclose(M[:,3]/norm(M[:,3]),U_A[:,1]))\n",
    "print(np.allclose(M[:,4]/norm(M[:,4]),U_A[:,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Explain why this makes sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible that the columns of M and columns of U_A will be out of order because the eigenvalues are simply the diagonal elements of the diagonal matrix, but they may be listed in a different order due to the algorithm used to compute them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2a. Make a random symmetric 3x3 matrix using the code below.  (A symmetrix matrix is equal to its own transpose.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37451746, 0.75833217, 1.31750618],\n",
       "       [0.75833217, 1.20997381, 0.89849543],\n",
       "       [1.31750618, 0.89849543, 1.15257419]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=np.random.rand(3,3)\n",
    "C=C+np.transpose(C)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Run power iteration to find the largest eigenvalue and a corresponding eigenvector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout=poweriter(C,np.random.rand(3),1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use Matlab code to directly find the eigenvectors and eigenvalues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.93600724 -0.6138483   0.41490651]\n",
      "[[-0.50373875 -0.81308979  0.29177435]\n",
      " [-0.56257265  0.05245654 -0.82508201]\n",
      " [-0.65556028  0.57977005  0.48384647]]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = eig(C)\n",
    "print(eigenvalues)\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dont have Matlab so I ran the command used above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
